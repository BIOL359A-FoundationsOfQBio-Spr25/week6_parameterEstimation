{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A | Parameter Estimation and Regularization\n",
    "### Spring 2025, Week 6\n",
    "Objectives:\n",
    "- Gain intuition for parameter estimation strategy (cross validation)\n",
    "- Explore the impact of initial conditions on the overall trajectory of the epidemic and final outcomes.\n",
    "- Identify the initial conditions that create stable steady-state in a one-variable example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.integrate import solve_ivp\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, FloatText, IntText, widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data\n",
    "Today we will start by working with in-silico data. The code below will generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples=100, degree=3, noise_level=0.5, x_range=(-3, 3)):\n",
    "    \"\"\"\n",
    "    Generate synthetic data with polynomial relationship and controlled noise.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Number of samples to generate\n",
    "    degree : int\n",
    "        True polynomial degree of the data\n",
    "    noise_level : float\n",
    "        Standard deviation of the Gaussian noise\n",
    "    x_range : tuple\n",
    "        Range of x values (min, max)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : ndarray of shape (n_samples,)\n",
    "        Feature values\n",
    "    y : ndarray of shape (n_samples,)\n",
    "        Target values with noise\n",
    "    true_coef : ndarray\n",
    "        True coefficients used to generate data\n",
    "    \"\"\"\n",
    "    # Generate random x values within the specified range\n",
    "    np.random.seed(42)\n",
    "    X = np.random.uniform(x_range[0], x_range[1], n_samples)\n",
    "    \n",
    "    # Generate random coefficients for polynomial\n",
    "    true_coef = np.random.randn(degree + 1)\n",
    "    true_coef = true_coef / np.max(np.abs(true_coef)) * 3  # Scale coefficients\n",
    "    \n",
    "    # Generate y values based on polynomial relationship\n",
    "    y_true = np.zeros(n_samples)\n",
    "    for i in range(degree + 1):\n",
    "        y_true += true_coef[i] * X**i\n",
    "    \n",
    "    # Add noise\n",
    "    y = y_true + noise_level * np.random.randn(n_samples)\n",
    "    X = X.reshape(-1, 1)\n",
    "    return X, y, true_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress only ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "def get_model(model_type='None', alpha=1.0, l1_ratio=0.5):\n",
    "    \"\"\"Create model based on regularization choice.\"\"\"\n",
    "    if model_type == 'Lasso':\n",
    "        return Lasso(alpha=alpha, max_iter=10000)\n",
    "    elif model_type == 'Ridge':\n",
    "        return Ridge(alpha=alpha)\n",
    "    elif model_type == 'Elastic':\n",
    "        return ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=10000)\n",
    "    else:\n",
    "        return LinearRegression()\n",
    "\n",
    "def create_polynomial_features(X, degree):\n",
    "    \"\"\"Create polynomial features from input data.\"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "    return poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(X, y, test_degree, n_folds=5, model_type='None', alpha=1.0, l1_ratio=0.5, plot_huge_loss=False):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for polynomial regression.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray\n",
    "        Input features\n",
    "    y : ndarray\n",
    "        Target values\n",
    "    test_degree : int\n",
    "        Degree of polynomial to test\n",
    "    n_folds : int\n",
    "        Number of folds for cross-validation\n",
    "    model_type : str\n",
    "        Type of regularization to use\n",
    "    alpha : float\n",
    "        Regularization strength\n",
    "    l1_ratio : float\n",
    "        Mixing parameter for ElasticNet\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    cv_results : dict\n",
    "        Dictionary with cross-validation results\n",
    "    \"\"\"\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=test_degree, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    # Initialize k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize lists to store results\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_coefs = []\n",
    "    fold_intercepts = []\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        # Split data into train and validation sets\n",
    "        # Important: We split the original features first, then transform\n",
    "        X_train_original, X_val_original = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Apply polynomial transformation to each fold separately\n",
    "        # This prevents data leakage between folds\n",
    "        poly_fold = PolynomialFeatures(degree=test_degree, include_bias=True)\n",
    "        X_train = poly_fold.fit_transform(X_train_original)\n",
    "        X_val = poly_fold.transform(X_val_original)  # Use same transformation\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = get_model(model_type, alpha, l1_ratio)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Calculate train and validation losses\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        train_loss = mean_squared_error(y_train, y_train_pred)\n",
    "        val_loss = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        # Store results\n",
    "        fold_train_losses.append(train_loss)\n",
    "        fold_val_losses.append(val_loss)\n",
    "        if val_loss > 10000 and plot_huge_loss:\n",
    "            fig, ax = plt.subplots(figsize=(14/3, 5))\n",
    "            ax.scatter(X_train_original, y_train, label='train')\n",
    "            ax.scatter(X_val_original, y_val, label='val')\n",
    "            \n",
    "            X_flat = X_train_original.flatten()\n",
    "            X_line = np.linspace(min(min(X_flat), min(X_val_original.flatten())), max(max(X_flat), max(X_val_original.flatten())), 10000).reshape(-1, 1)\n",
    "            X_poly_line = create_polynomial_features(X_line, test_degree)\n",
    "            y_pred = model.predict(X_poly_line)\n",
    "            ax.plot(X_line, y_pred, 'g-', linewidth=2, label=f'Model fit (degree={test_degree})')\n",
    "            ax.legend()\n",
    "            ax.set_xlabel(\"X\")\n",
    "            ax.set_ylabel(\"Y\")\n",
    "            ax.set_title(f\"Data and Model fit (degree = {test_degree})\")\n",
    "            \n",
    "            \n",
    "        # Store model parameters\n",
    "        if hasattr(model, 'coef_'):\n",
    "            fold_coefs.append(model.coef_)\n",
    "        else:\n",
    "            fold_coefs.append(None)\n",
    "            \n",
    "        if hasattr(model, 'intercept_'):\n",
    "            fold_intercepts.append(model.intercept_)\n",
    "        else:\n",
    "            fold_intercepts.append(None)\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_train_loss = np.mean(fold_train_losses)\n",
    "    avg_val_loss = np.mean(fold_val_losses)\n",
    "    \n",
    "    # Create dictionary with results\n",
    "    cv_results = {\n",
    "        'fold_train_losses': fold_train_losses,\n",
    "        'fold_val_losses': fold_val_losses,\n",
    "        'fold_coefs': fold_coefs,\n",
    "        'fold_intercepts': fold_intercepts,\n",
    "        'avg_train_loss': avg_train_loss,\n",
    "        'avg_val_loss': avg_val_loss\n",
    "    }\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "# This function is no longer needed since we're handling the train-test split \n",
    "# in the main cross_validate_and_visualize function\n",
    "# Keeping definition for backward compatibility but marking as deprecated\n",
    "def train_test_model(X, y, test_degree, test_size=0.2, model_type='None', alpha=1.0, l1_ratio=0.5):\n",
    "    \"\"\"\n",
    "    DEPRECATED: Use direct train-test split in cross_validate_and_visualize instead\n",
    "    \n",
    "    Train model on train set and evaluate on test set.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray\n",
    "        Input features\n",
    "    y : ndarray\n",
    "        Target values\n",
    "    test_degree : int\n",
    "        Degree of polynomial to test\n",
    "    test_size : float\n",
    "        Proportion of data to use for testing\n",
    "    model_type : str\n",
    "        Type of regularization to use\n",
    "    alpha : float\n",
    "        Regularization strength\n",
    "    l1_ratio : float\n",
    "        Mixing parameter for ElasticNet\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    test_results : dict\n",
    "        Dictionary with test results\n",
    "    \"\"\"\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=test_degree, include_bias=True)\n",
    "    \n",
    "    # Split data into train and test sets - split original data first\n",
    "    X_train_orig, X_test_orig, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Apply polynomial transformation after splitting\n",
    "    X_train = poly.fit_transform(X_train_orig)\n",
    "    X_test = poly.transform(X_test_orig)\n",
    "    \n",
    "    # Create and fit model\n",
    "    model = get_model(model_type, alpha, l1_ratio)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate train and test losses\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_loss = mean_squared_error(y_train, y_train_pred)\n",
    "    test_loss = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    # Create dictionary with results\n",
    "    test_results = {\n",
    "        'train_loss': train_loss,\n",
    "        'test_loss': test_loss,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_polynomial_regression():\n",
    "    @interact(\n",
    "        true_degree=widgets.IntSlider(min=1, max=9, step=1, value=3, description='True Degree:'),\n",
    "        noise_level=widgets.FloatSlider(min=0.1, max=20.0, step=0.1, value=0.1, description='Noise Level:'),\n",
    "        n_samples=widgets.IntSlider(min=20, max=200, step=10, value=100, description='Sample Size:'),\n",
    "        test_degree=widgets.IntSlider(min=1, max=15, step=1, value=3, description='Test Degree:'),\n",
    "        regularization=widgets.RadioButtons(\n",
    "            options=['None', 'Lasso', 'Ridge', 'Elastic'],\n",
    "            value='None',\n",
    "            description='Regularization:'\n",
    "        ),\n",
    "        alpha=widgets.FloatLogSlider(\n",
    "            min=-5, max=1, step=0.1, value=0.1, base=10, description='Alpha (Reg. Strength):'\n",
    "        ),\n",
    "        l1_ratio=widgets.FloatSlider(\n",
    "            min=0.0, max=1.0, step=0.05, value=0.5, description='L1 Ratio (Elastic):'\n",
    "        ),\n",
    "        n_folds=widgets.IntSlider(min=3, max=15, step=1, value=5, description='CV Folds:'),\n",
    "        plot_huge_loss=widgets.RadioButtons(\n",
    "            options=[False, True],\n",
    "            value=False,\n",
    "            description='Plot val loss'\n",
    "        )\n",
    "    )\n",
    "    def cross_validate_and_visualize(true_degree, noise_level, n_samples, test_degree,\n",
    "                                    regularization, alpha, l1_ratio, n_folds, plot_huge_loss):\n",
    "        # Generate synthetic data\n",
    "        X, y, true_coef = generate_data(n_samples, true_degree, noise_level)\n",
    "        \n",
    "        # First split into train and test sets\n",
    "        X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Perform cross-validation on training data only\n",
    "        cv_results = perform_cross_validation(\n",
    "            X_train_full, y_train_full, test_degree, n_folds, regularization, alpha, l1_ratio, plot_huge_loss\n",
    "        )\n",
    "        \n",
    "        # Train final model on all training data and evaluate on test set\n",
    "        # Create polynomial features for train and test\n",
    "        poly = PolynomialFeatures(degree=test_degree, include_bias=True)\n",
    "        X_train_poly = poly.fit_transform(X_train_full)\n",
    "        X_test_poly = poly.transform(X_test)\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = get_model(regularization, alpha, l1_ratio)\n",
    "        model.fit(X_train_poly, y_train_full)\n",
    "        \n",
    "        # Calculate train and test losses\n",
    "        y_train_pred = model.predict(X_train_poly)\n",
    "        y_test_pred = model.predict(X_test_poly)\n",
    "        \n",
    "        train_loss = mean_squared_error(y_train_full, y_train_pred)\n",
    "        test_loss = mean_squared_error(y_test, y_test_pred)\n",
    "        \n",
    "        # Create dictionary with test results\n",
    "        test_results = {\n",
    "            'train_loss': train_loss,\n",
    "            'test_loss': test_loss,\n",
    "            'model': model\n",
    "        }\n",
    "        \n",
    "        # Create figure with 3 subplots\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "        \n",
    "        # Plot 1: Data and model fit\n",
    "        ax1 = axes[0]\n",
    "        \n",
    "        # Plot original data\n",
    "        X_flat = X_train_full.flatten()\n",
    "        X_test_flat = X_test.flatten()\n",
    "        ax1.scatter(X_flat, y_train_full, alpha=0.6, label='Data points (Train)')\n",
    "        ax1.scatter(X_test_flat, y_test, alpha=0.6, label='Data points (Test)')\n",
    "        \n",
    "        # Plot true function\n",
    "        X_line = np.linspace(min(X_flat), max(X_flat), 100).reshape(-1, 1)\n",
    "        y_true = np.zeros(100)\n",
    "        for i in range(true_degree + 1):\n",
    "            y_true += true_coef[i] * X_line.flatten()**i\n",
    "        ax1.plot(X_line, y_true, 'r-', linewidth=2, label='True function')\n",
    "        \n",
    "        # Plot model fit\n",
    "        X_poly_line = create_polynomial_features(X_line, test_degree)\n",
    "        y_pred = test_results['model'].predict(X_poly_line)\n",
    "        ax1.plot(X_line, y_pred, 'g-', linewidth=2, label=f'Model fit (degree={test_degree})')\n",
    "        \n",
    "        ax1.set_title(f'Data and Model Fit\\nTrue degree: {true_degree}, Test degree: {test_degree}')\n",
    "        ax1.set_xlabel('X')\n",
    "        ax1.set_ylabel('y')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Plot 2: Validation loss for each fold\n",
    "        ax2 = axes[1]\n",
    "        \n",
    "        folds = list(range(1, n_folds + 1))\n",
    "        ax2.bar(\n",
    "            [f - 0.2 for f in folds], \n",
    "            cv_results['fold_train_losses'], \n",
    "            width=0.4, \n",
    "            color='blue', \n",
    "            alpha=0.6, \n",
    "            label='Train Loss'\n",
    "        )\n",
    "        ax2.bar(\n",
    "            [f + 0.2 for f in folds], \n",
    "            cv_results['fold_val_losses'], \n",
    "            width=0.4, \n",
    "            color='red', \n",
    "            alpha=0.6, \n",
    "            label='Validation Loss'\n",
    "        )\n",
    "        \n",
    "        ax2.axhline(\n",
    "            cv_results['avg_train_loss'], \n",
    "            color='blue', \n",
    "            linestyle='--', \n",
    "            alpha=0.8,\n",
    "            label=f'Avg Train Loss: {cv_results[\"avg_train_loss\"]:.4f}'\n",
    "        )\n",
    "        ax2.axhline(\n",
    "            cv_results['avg_val_loss'], \n",
    "            color='red', \n",
    "            linestyle='--', \n",
    "            alpha=0.8,\n",
    "            label=f'Avg Val Loss: {cv_results[\"avg_val_loss\"]:.4f}'\n",
    "        )\n",
    "        ax2.axhline(\n",
    "            test_results['test_loss'], \n",
    "            color='green', \n",
    "            linestyle='--', \n",
    "            alpha=0.8,\n",
    "            label=f'Test Loss: {test_results[\"test_loss\"]:.4f}'\n",
    "        )\n",
    "        \n",
    "        ax2.set_title(f'Train and Validation Loss for Each Fold\\n({n_folds}-fold Cross-Validation)')\n",
    "        ax2.set_xlabel('Fold')\n",
    "        ax2.set_ylabel('Mean Squared Error')\n",
    "        ax2.set_xticks(folds)\n",
    "        ax2.legend()\n",
    "        \n",
    "        # Plot 3: Train, validation, test loss comparison across model complexities\n",
    "        ax3 = axes[2]\n",
    "        \n",
    "        # Evaluate models with different degrees\n",
    "        degrees = list(range(1, 16))\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        test_losses = []\n",
    "        \n",
    "        for degree in degrees:\n",
    "            # Perform cross-validation\n",
    "            cv_res = perform_cross_validation(\n",
    "                X, y, degree, n_folds, regularization, alpha, l1_ratio\n",
    "            )\n",
    "            \n",
    "            # Train final model on all data and evaluate on test set\n",
    "            test_res = train_test_model(\n",
    "                X, y, degree, 0.2, regularization, alpha, l1_ratio\n",
    "            )\n",
    "            \n",
    "            train_losses.append(cv_res['avg_train_loss'])\n",
    "            val_losses.append(cv_res['avg_val_loss'])\n",
    "            test_losses.append(test_res['test_loss'])\n",
    "        \n",
    "        ax3.plot(degrees, train_losses, 'o-', color='blue', label='Train Loss')\n",
    "        ax3.plot(degrees, val_losses, 'o-', color='red', label='Validation Loss')\n",
    "        ax3.plot(degrees, test_losses, 'o-', color='green', label='Test Loss')\n",
    "        \n",
    "        ax3.axvline(\n",
    "            true_degree, \n",
    "            color='black', \n",
    "            linestyle='--', \n",
    "            alpha=0.5,\n",
    "            label=f'True Degree: {true_degree}'\n",
    "        )\n",
    "        \n",
    "        ax3.set_title('Model Performance vs. Complexity')\n",
    "        ax3.set_xlabel('Polynomial Degree')\n",
    "        ax3.set_ylabel('Mean Squared Error')\n",
    "        ax3.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(\"\\n=== Cross-Validation Results ===\\n\")\n",
    "        coefs_array = np.array(cv_results['fold_coefs'])\n",
    "        # Create a DataFrame for fold-by-fold results\n",
    "        fold_results = pd.DataFrame({\n",
    "            'Fold': list(range(1, n_folds + 1)),\n",
    "            'Train Loss': cv_results['fold_train_losses'],\n",
    "            'Validation Loss': cv_results['fold_val_losses']\n",
    "        })\n",
    "        \n",
    "        print(fold_results)\n",
    "        \n",
    "        print(f\"\\nAverage Train Loss: {cv_results['avg_train_loss']:.4f}\")\n",
    "        print(f\"Average Validation Loss: {cv_results['avg_val_loss']:.4f}\")\n",
    "        print(f\"Test Loss: {test_results['test_loss']:.4f}\")\n",
    "        \n",
    "        print(\"\\n=== Model Parameters for Each Fold ===\\n\")\n",
    "        \n",
    "        # Create a DataFrame for model parameters\n",
    "        param_cols = [f'Coef {i}' if i > 0 else 'Intercept' for i in range(coefs_array.shape[1])]\n",
    "        coefs_array[:, 0] = cv_results['fold_intercepts']\n",
    "        param_data = pd.DataFrame(coefs_array, columns=param_cols)\n",
    "        param_data.insert(0, 'Fold', list(range(1, n_folds + 1)))\n",
    "        \n",
    "        print(param_data)\n",
    "        \n",
    "        # Print true coefficients\n",
    "        print(\"\\n=== True Coefficients ===\\n\")\n",
    "        true_coef_names = [f'Coef {i}' if i > 0 else 'Intercept' for i in range(len(true_coef))]\n",
    "        true_coef_df = pd.DataFrame([true_coef], columns=true_coef_names)\n",
    "        print(true_coef_df)\n",
    "\n",
    "\n",
    "# Run the interactive application\n",
    "interactive_polynomial_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write equations for diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-variable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ODE system for a single variable\n",
    "def ode_system(t, x):\n",
    "    # dx/dt = -0.1(x-1)(x-2)(x-4)\n",
    "    dxdt = -0.1 * (x - 1) * (x - 2) * (x - 4)\n",
    "    return [dxdt]\n",
    "\n",
    "# Function to solve and plot the system\n",
    "def plot_ode_solution(x_init=0.5, t_max=20):\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Solve the ODE system\n",
    "    t_span = (0, t_max)\n",
    "    t_eval = np.linspace(0, t_max, 1000)\n",
    "    initial_conditions = [x_init]\n",
    "    \n",
    "    solution = solve_ivp(\n",
    "        ode_system, \n",
    "        t_span, \n",
    "        initial_conditions, \n",
    "        method='RK45', \n",
    "        t_eval=t_eval\n",
    "    )\n",
    "    \n",
    "    t = solution.t\n",
    "    x = solution.y[0]\n",
    "    \n",
    "    # Plot the solution trajectory\n",
    "    plt.plot(t, x, 'b-', linewidth=2, label='x(t)')\n",
    "    plt.axhline(y=1, color='r', linestyle='--', alpha=0.6, label='x=1 (equilibrium)')\n",
    "    plt.axhline(y=2, color='g', linestyle='--', alpha=0.6, label='x=2 (equilibrium)')\n",
    "    plt.axhline(y=4, color='m', linestyle='--', alpha=0.6, label='x=4 (equilibrium)')\n",
    "    \n",
    "    plt.xlabel('Time (t)', fontsize=12)\n",
    "    plt.ylabel('x', fontsize=12)\n",
    "    plt.title(f'Solution vs Time (Initial: x={x_init})', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Add phase line diagram (direction field on x-axis)\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    x_range = np.linspace(-1, 6, 1000)\n",
    "    dxdt = -0.1 * (x_range - 1) * (x_range - 2) * (x_range - 4)\n",
    "    \n",
    "    plt.plot(x_range, dxdt, 'k-', linewidth=2)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-', alpha=0.6)\n",
    "    plt.axvline(x=1, color='r', linestyle='--', alpha=0.6)\n",
    "    plt.axvline(x=2, color='g', linestyle='--', alpha=0.6)\n",
    "    plt.axvline(x=4, color='m', linestyle='--', alpha=0.6)\n",
    "    \n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('dx/dt', fontsize=12)\n",
    "    plt.title('Phase Line Diagram: dx/dt vs x', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add arrows to show direction\n",
    "    for x_val in [0, 1.5, 3, 5]:\n",
    "        derivative = -0.1 * (x_val - 1) * (x_val - 2) * (x_val - 4)\n",
    "        direction = 'right' if derivative > 0 else 'left'\n",
    "        plt.annotate('', xy=(x_val + 0.3 if direction == 'right' else x_val - 0.3, 0), \n",
    "                    xytext=(x_val, 0),\n",
    "                    arrowprops=dict(arrowstyle=\"->\", color='blue'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  \n",
    "# Create interactive widget\n",
    "interact(\n",
    "    plot_ode_solution,\n",
    "    x_init=FloatSlider(min=-1.0, max=6.0, step=0.1, value=0.5, description='x(0):'),\n",
    "    t_max=FloatSlider(min=5.0, max=50.0, step=1.0, value=10.0, description='Max Time:'),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, fixed\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the SIR model with births and deaths\n",
    "def sir_model(t, y, r_B, r_S, r_I, r_R, r_D):\n",
    "    S, I, R = y\n",
    "    # Model equations\n",
    "    dSdt = r_B + r_S*R - r_I*S*I    # Susceptible population change\n",
    "    dIdt = r_I*S*I - r_R*I - r_D*I   # Infected population change \n",
    "    dRdt = r_R*I - r_S*R             # Recovered population change\n",
    "    \n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "# Function to solve and visualize the SIR model\n",
    "def plot_sir_model(S_init=0.9, I_init=0.1, R_init=0.0, \n",
    "                  r_B=0.05, r_S=0.1, r_I=0.3, r_R=0.1, r_D=0.01, \n",
    "                  t_max=100, total_population=10000):\n",
    "    \n",
    "    # Ensure initial populations sum to 1 (normalized)\n",
    "    total_frac = S_init + I_init + R_init\n",
    "    S_init, I_init, R_init = S_init/total_frac, I_init/total_frac, R_init/total_frac\n",
    "    \n",
    "    # Solve the ODE system\n",
    "    t_span = (0, t_max)\n",
    "    t_eval = np.linspace(0, t_max, int(t_max))\n",
    "    initial_conditions = [S_init, I_init, R_init]\n",
    "    solution = solve_ivp(\n",
    "        lambda t, y: sir_model(t, y, r_B, r_S, r_I, r_R, r_D), \n",
    "        t_span, \n",
    "        initial_conditions, \n",
    "        method='RK45', \n",
    "        t_eval=t_eval\n",
    "    )\n",
    "    \n",
    "    t = solution.t\n",
    "    S = solution.y[0]\n",
    "    I = solution.y[1]\n",
    "    R = solution.y[2]\n",
    "    N = S + I + R  # Total population (as fraction)\n",
    "    # Convert fractions to numbers of individuals\n",
    "    S_count = S * total_population\n",
    "    I_count = I * total_population\n",
    "    R_count = R * total_population\n",
    "    N_count = N * total_population\n",
    "    \n",
    "    # Create separate figures for better compatibility with Colab\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(t, S_count, 'b-', linewidth=2, label='Susceptible (S)')\n",
    "    plt.plot(t, I_count, 'r-', linewidth=2, label='Infected (I)')\n",
    "    plt.plot(t, R_count, 'g-', linewidth=2, label='Recovered (R)')\n",
    "    \n",
    "    plt.xlabel('Time', fontsize=12)\n",
    "    plt.ylabel('Number of Individuals', fontsize=12)\n",
    "    plt.title('SIR Model with Births, Deaths and Reinfection', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    # Display equations and parameters on the plot\n",
    "    eqn_text = \"SIR Model Equations:\\n\" \\\n",
    "              \"dS/dt = r_B + r_S*R - r_I*S*I\\n\" \\\n",
    "              \"dI/dt = r_I*S*I - r_R*I - r_D*I\\n\" \\\n",
    "              \"dR/dt = r_R*I - r_S*R\"\n",
    "    plt.figtext(0.02, 0.02, eqn_text, fontsize=10, bbox=dict(facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analysis\n",
    "    print(\"Model Analysis:\")\n",
    "    print(f\"Initial conditions: S(0)={int(S_init * total_population)} individuals, \" +\n",
    "          f\"I(0)={int(I_init * total_population)} individuals, \" +\n",
    "          f\"R(0)={int(R_init * total_population)} individuals\")\n",
    "    print(f\"Final values: S({t_max})={int(S[-1] * total_population)} individuals, \" +\n",
    "          f\"I({t_max})={int(I[-1] * total_population)} individuals, \" +\n",
    "          f\"R({t_max})={int(R[-1] * total_population)} individuals\")\n",
    "    print(f\"Total final population: {int(N[-1] * total_population)} individuals\")\n",
    "\n",
    "# Create text input widgets for initial conditions and parameters\n",
    "w_S_init = FloatText(value=0.99, description='S(0) fraction:')\n",
    "w_I_init = FloatText(value=0.01, description='I(0) fraction:')\n",
    "w_R_init = FloatText(value=0.0, description='R(0) fraction:')\n",
    "\n",
    "w_r_B = FloatText(value=0.03, description='r_B (birth):')\n",
    "w_r_S = FloatText(value=0.01, description='r_S (suscept):')\n",
    "w_r_I = FloatText(value=0.5, description='r_I (infection):')\n",
    "w_r_R = FloatText(value=0.05, description='r_R (recovery):')\n",
    "w_r_D = FloatText(value=0.02, description='r_D (death):')\n",
    "w_t_max = FloatText(value=100, description='Max time:')\n",
    "w_population = IntText(value=1000, description='Population:')\n",
    "# Link the interact function to the UI\n",
    "widgets = {\n",
    "    'S_init': w_S_init,\n",
    "    'I_init': w_I_init,\n",
    "    'R_init': w_R_init,\n",
    "    'r_B': w_r_B,\n",
    "    'r_S': w_r_S,\n",
    "    'r_I': w_r_I,\n",
    "    'r_R': w_r_R,\n",
    "    'r_D': w_r_D,\n",
    "    't_max': w_t_max,\n",
    "    'total_population': w_population\n",
    "}\n",
    "\n",
    "# Display the interactive model\n",
    "interact(plot_sir_model, **widgets);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis for SIR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image(\"images/SIR.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from ipywidgets import interact, widgets, HBox, VBox, Layout\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the SIR model with births and deaths\n",
    "def sir_model(t, y, r_B, r_S, r_I, r_R, r_D):\n",
    "    S, I, R = y\n",
    "    # Model equations\n",
    "    dSdt = r_B + r_S*R - r_I*S*I    # Susceptible population change\n",
    "    dIdt = r_I*S*I - r_R*I - r_D*I   # Infected population change \n",
    "    dRdt = r_R*I - r_S*R             # Recovered population change\n",
    "    \n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "# Function to solve the SIR model for a specific set of parameters\n",
    "def solve_sir_model(S_init, I_init, R_init, r_B, r_S, r_I, r_R, r_D, t_max):\n",
    "    # Ensure initial populations sum to 1 (normalized)\n",
    "    total_frac = S_init + I_init + R_init\n",
    "    S_init, I_init, R_init = S_init/total_frac, I_init/total_frac, R_init/total_frac\n",
    "    \n",
    "    # Solve the ODE system\n",
    "    t_span = (0, t_max)\n",
    "    t_eval = np.linspace(0, t_max, int(t_max))\n",
    "    initial_conditions = [S_init, I_init, R_init]\n",
    "    solution = solve_ivp(\n",
    "        lambda t, y: sir_model(t, y, r_B, r_S, r_I, r_R, r_D), \n",
    "        t_span, \n",
    "        initial_conditions, \n",
    "        method='RK45', \n",
    "        t_eval=t_eval\n",
    "    )\n",
    "    \n",
    "    return solution.t, solution.y\n",
    "\n",
    "# Function to plot sensitivity analysis\n",
    "def plot_sensitivity_analysis(S_init=0.99, I_init=0.01, R_init=0.0,\n",
    "                             r_B=0.03, r_S=0.01, r_R=0.05, r_D=0.02,\n",
    "                             t_max=100, total_population=1000,\n",
    "                             infection_rates=\"0.3, 0.5, 0.7\",\n",
    "                             plot_susceptible=True, plot_infected=True, plot_recovered=True):\n",
    "    \n",
    "    # Parse the infection rates from the input string\n",
    "    try:\n",
    "        r_I_values = [float(rate.strip()) for rate in infection_rates.split(',')]\n",
    "    except ValueError:\n",
    "        print(\"Error: Please enter valid infection rates as comma-separated numbers.\")\n",
    "        return\n",
    "    \n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Line styles and colors for different compartments\n",
    "    line_styles = {'S': ('blue', '-'), 'I': ('red', '-'), 'R': ('green', '-')}\n",
    "    \n",
    "    # Dictionary to store results for analysis\n",
    "    results = {}\n",
    "    \n",
    "    # Solve and plot for each infection rate\n",
    "    for i, r_I in enumerate(r_I_values):\n",
    "        # Solve the model with this infection rate\n",
    "        t, solution = solve_sir_model(S_init, I_init, R_init, r_B, r_S, r_I, r_R, r_D, t_max)\n",
    "        \n",
    "        # Extract the results\n",
    "        S = solution[0]\n",
    "        I = solution[1]\n",
    "        R = solution[2]\n",
    "        \n",
    "        # Store peak infection and time for analysis\n",
    "        peak_infection = max(I)\n",
    "        peak_time = t[np.argmax(I)]\n",
    "        final_recovered = R[-1]\n",
    "        \n",
    "        results[r_I] = {\n",
    "            'peak_infection': peak_infection,\n",
    "            'peak_time': peak_time,\n",
    "            'final_recovered': final_recovered\n",
    "        }\n",
    "        \n",
    "        # Convert to actual population numbers\n",
    "        S_count = S * total_population\n",
    "        I_count = I * total_population\n",
    "        R_count = R * total_population\n",
    "        \n",
    "        # Adjust line style for different infection rates\n",
    "        ls_mod = ['-', '--', ':', '-.'][i % 4]\n",
    "        \n",
    "        # Plot selected compartments\n",
    "        if plot_susceptible:\n",
    "            plt.plot(t, S_count, color=line_styles['S'][0], linestyle=ls_mod, \n",
    "                    label=f'S (r_I={r_I})')\n",
    "        if plot_infected:\n",
    "            plt.plot(t, I_count, color=line_styles['I'][0], linestyle=ls_mod, \n",
    "                    label=f'I (r_I={r_I})')\n",
    "        if plot_recovered:\n",
    "            plt.plot(t, R_count, color=line_styles['R'][0], linestyle=ls_mod, \n",
    "                    label=f'R (r_I={r_I})')\n",
    "    \n",
    "    plt.xlabel('Time', fontsize=12)\n",
    "    plt.ylabel('Number of Individuals', fontsize=12)\n",
    "    plt.title('SIR Model Sensitivity Analysis: Effect of Infection Rate', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print analysis\n",
    "    print(\"\\nSensitivity Analysis Results:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Infection Rate':<15} {'Peak Infected':<20} {'Time to Peak':<15} {'Total Infected':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for r_I, data in results.items():\n",
    "        print(f\"{r_I:<15.3f} {data['peak_infection']*total_population:<20.1f} {data['peak_time']:<15.1f} {data['final_recovered']*total_population:<15.1f}\")\n",
    "\n",
    "# Create input widgets\n",
    "w_S_init = widgets.FloatText(value=0.99, description='S(0) fraction:', style={'description_width': 'initial'})\n",
    "w_I_init = widgets.FloatText(value=0.01, description='I(0) fraction:', style={'description_width': 'initial'})\n",
    "w_R_init = widgets.FloatText(value=0.0, description='R(0) fraction:', style={'description_width': 'initial'})\n",
    "\n",
    "w_r_B = widgets.FloatText(value=0.03, description='r_B (birth):', style={'description_width': 'initial'})\n",
    "w_r_S = widgets.FloatText(value=0.01, description='r_S (suscept):', style={'description_width': 'initial'})\n",
    "w_r_R = widgets.FloatText(value=0.05, description='r_R (recovery):', style={'description_width': 'initial'})\n",
    "w_r_D = widgets.FloatText(value=0.02, description='r_D (death):', style={'description_width': 'initial'})\n",
    "\n",
    "w_t_max = widgets.FloatText(value=100, description='Max time:', style={'description_width': 'initial'})\n",
    "w_population = widgets.IntText(value=1000, description='Population:', style={'description_width': 'initial'})\n",
    "w_infection_rates = widgets.Text(\n",
    "    value='0.3, 0.5, 0.7',\n",
    "    description='Infection rates:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Checkboxes for selecting which curves to plot\n",
    "w_plot_susceptible = widgets.Checkbox(value=True, description='Plot Susceptible (S)')\n",
    "w_plot_infected = widgets.Checkbox(value=True, description='Plot Infected (I)')\n",
    "w_plot_recovered = widgets.Checkbox(value=True, description='Plot Recovered (R)')\n",
    "\n",
    "interact_manual = interact(\n",
    "    plot_sensitivity_analysis,\n",
    "    S_init=w_S_init,\n",
    "    I_init=w_I_init,\n",
    "    R_init=w_R_init,\n",
    "    r_B=w_r_B,\n",
    "    r_S=w_r_S,\n",
    "    r_R=w_r_R,\n",
    "    r_D=w_r_D,\n",
    "    t_max=w_t_max,\n",
    "    total_population=w_population,\n",
    "    infection_rates=w_infection_rates,\n",
    "    plot_susceptible=w_plot_susceptible,\n",
    "    plot_infected=w_plot_infected,\n",
    "    plot_recovered=w_plot_recovered\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAIR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image(\"images/SIAR.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SAIR model with asymptomatic cases\n",
    "def sair_model(t, y, r_B, r_S, r_I, r_A, r_RI, r_RA, r_DI, r_DA):\n",
    "    S, A, I, R = y\n",
    "    \n",
    "    # Model equations\n",
    "    dSdt = r_B + r_S*R - r_I*S*I - r_A*S*A     # Susceptible population change\n",
    "    dAdt = r_A*S*A - r_RA*A - r_DA*A           # Asymptomatic population change\n",
    "    dIdt = r_I*S*I - r_RI*I - r_DI*I           # Infected/symptomatic population change\n",
    "    dRdt = r_RI*I + r_RA*A - r_S*R             # Recovered population change\n",
    "    \n",
    "    return [dSdt, dAdt, dIdt, dRdt]\n",
    "\n",
    "# Function to solve and visualize the SAIR model\n",
    "def plot_sair_model(S_init=0.99, A_init=0.005, I_init=0.005, R_init=0.0, \n",
    "                   r_B=0.03, r_S=0.01, r_I=0.5, r_A=0.3, \n",
    "                   r_RI=0.05, r_RA=0.07, r_DI=0.02, r_DA=0.005, \n",
    "                   t_max=100, total_population=1000):\n",
    "    \n",
    "    # Ensure initial populations sum to 1 (normalized)\n",
    "    total_frac = S_init + A_init + I_init + R_init\n",
    "    S_init, A_init, I_init, R_init = S_init/total_frac, A_init/total_frac, I_init/total_frac, R_init/total_frac\n",
    "    \n",
    "    # Solve the ODE system\n",
    "    t_span = (0, t_max)\n",
    "    t_eval = np.linspace(0, t_max, int(t_max))\n",
    "    initial_conditions = [S_init, A_init, I_init, R_init]\n",
    "    \n",
    "    solution = solve_ivp(\n",
    "        lambda t, y: sair_model(t, y, r_B, r_S, r_I, r_A, r_RI, r_RA, r_DI, r_DA), \n",
    "        t_span, \n",
    "        initial_conditions, \n",
    "        method='RK45', \n",
    "        t_eval=t_eval\n",
    "    )\n",
    "    \n",
    "    t = solution.t\n",
    "    S = solution.y[0]\n",
    "    A = solution.y[1]\n",
    "    I = solution.y[2]\n",
    "    R = solution.y[3]\n",
    "    N = S + A + I + R  # Total population (as fraction)\n",
    "    \n",
    "    # Convert fractions to numbers of individuals\n",
    "    S_count = S * total_population\n",
    "    A_count = A * total_population\n",
    "    I_count = I * total_population\n",
    "    R_count = R * total_population\n",
    "    N_count = N * total_population\n",
    "    \n",
    "    # Create separate figures for better compatibility with Colab\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(t, S_count, 'b-', linewidth=2, label='Susceptible (S)')\n",
    "    plt.plot(t, A_count, 'm-', linewidth=2, label='Asymptomatic (A)')\n",
    "    plt.plot(t, I_count, 'r-', linewidth=2, label='Symptomatic (I)')\n",
    "    plt.plot(t, R_count, 'g-', linewidth=2, label='Recovered (R)')\n",
    "    plt.plot(t, A_count + I_count, 'y--', linewidth=1.5, label='Total Infected (A+I)')\n",
    "    \n",
    "    plt.xlabel('Time (days)', fontsize=12)\n",
    "    plt.ylabel('Number of Individuals', fontsize=12)\n",
    "    plt.title('SAIR Model with Asymptomatic Cases', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    # Display equations and parameters on the plot\n",
    "    eqn_text = \"SAIR Model Equations:\\n\" \\\n",
    "              \"dS/dt = r_B + r_S*R - r_I*S*I - r_A*S*A\\n\" \\\n",
    "              \"dA/dt = r_A*S*A - r_RA*A - r_DA*A\\n\" \\\n",
    "              \"dI/dt = r_I*S*I - r_RI*I - r_DI*I\\n\" \\\n",
    "              \"dR/dt = r_RI*I + r_RA*A - r_S*R\"\n",
    "    plt.figtext(0.02, 0.02, eqn_text, fontsize=10, bbox=dict(facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# Create text input widgets for initial conditions and parameters\n",
    "w_S_init = FloatText(value=0.99, description='S(0) fraction:')\n",
    "w_A_init = FloatText(value=0.005, description='A(0) fraction:')\n",
    "w_I_init = FloatText(value=0.005, description='I(0) fraction:')\n",
    "w_R_init = FloatText(value=0.0, description='R(0) fraction:')\n",
    "\n",
    "w_r_B = FloatText(value=0.03, description='r_B (birth):')\n",
    "w_r_S = FloatText(value=0.01, description='r_S (suscept):')\n",
    "w_r_I = FloatText(value=0.5, description='r_I (sympt infect):')\n",
    "w_r_A = FloatText(value=0.3, description='r_A (asympt infect):')\n",
    "w_r_RI = FloatText(value=0.05, description='r_RI (sympt recov):')\n",
    "w_r_RA = FloatText(value=0.07, description='r_RA (asympt recov):')\n",
    "w_r_DI = FloatText(value=0.02, description='r_DI (sympt death):')\n",
    "w_r_DA = FloatText(value=0.005, description='r_DA (asympt death):')\n",
    "w_t_max = FloatText(value=100, description='Max time (days):')\n",
    "w_population = IntText(value=1000, description='Population:')\n",
    "\n",
    "# Link the interact function to the UI\n",
    "widgets = {\n",
    "    'S_init': w_S_init,\n",
    "    'A_init': w_A_init,\n",
    "    'I_init': w_I_init,\n",
    "    'R_init': w_R_init,\n",
    "    'r_B': w_r_B,\n",
    "    'r_S': w_r_S,\n",
    "    'r_I': w_r_I,\n",
    "    'r_A': w_r_A,\n",
    "    'r_RI': w_r_RI,\n",
    "    'r_RA': w_r_RA,\n",
    "    'r_DI': w_r_DI,\n",
    "    'r_DA': w_r_DA,\n",
    "    't_max': w_t_max,\n",
    "    'total_population': w_population\n",
    "}\n",
    "\n",
    "# Display the interactive model\n",
    "interact(plot_sair_model, **widgets);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
